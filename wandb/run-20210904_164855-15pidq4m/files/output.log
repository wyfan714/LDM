
Random Sampling
Train Epoch: 0 [2/65 (2%)] Loss: 19.659245: : 1it [00:00,  1.17it/s]
Training parameters: {'LOG_DIR': '../Proxy_Anchor/Newlogs', 'dataset': 'cub', 'sz_embedding': 512, 'sz_batch': 90, 'nb_epochs': 40, 'gpu_id': 1, 'nb_workers': 2, 'model': 'bn_inception', 'loss': 'Proxy_Anchor', 'optimizer': 'adamw', 'lr': 0.0001, 'mrg_lr': 0.0005, 'weight_decay': 0.0001, 'weight_lambda': 0.3, 'lr_decay_step': 10, 'lr_decay_gamma': 0.5, 'mrg_lr_decay_step': 10, 'mrg_lr_decay_gamma': 0.5, 'alphap': 48.0, 'alphan': 48.0, 'mrg': 0.1, 'IPC': None, 'warm': 1, 'bn_freeze': 1, 'l2_norm': 1, 'remark': '', 'delta': 0.1, 'T': 1.0, 'lam': 1.0}








Train Epoch: 0 [65/65 (98%)] Loss: 14.744200: : 65it [00:15,  4.23it/s]
**Evaluating...**
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 50.456
R@2 : 63.825
R@4 : 76.199
R@8 : 85.213
R@16 : 91.847
R@32 : 95.949







Train Epoch: 1 [65/65 (98%)] Loss: 13.366340: : 65it [00:15,  4.33it/s]
**Evaluating...**
0it [00:00, ?it/s]
Computing t-SNE embedding
Train Epoch: 2 [4/65 (5%)] Loss: 12.471621: : 4it [00:01,  3.54it/s]
R@1 : 60.246
R@2 : 71.759
R@4 : 81.668
R@8 : 88.876
R@16 : 93.856






Train Epoch: 2 [55/65 (83%)] Loss: 11.161320: : 55it [00:12,  4.38it/s]


Train Epoch: 2 [65/65 (98%)] Loss: 10.974758: : 65it [00:15,  4.27it/s]
Computing t-SNE embedding
R@1 : 62.846
0it [00:00, ?it/s]
Train Epoch: 3 [2/65 (2%)] Loss: 11.466410: : 2it [00:00,  2.36it/s]
R@2 : 74.848
R@4 : 83.575
R@8 : 89.754
R@16 : 94.632







Train Epoch: 3 [63/65 (95%)] Loss: 9.698415: : 63it [00:14,  4.38it/s]

Train Epoch: 3 [65/65 (98%)] Loss: 9.952853: : 65it [00:15,  4.22it/s]
Computing t-SNE embedding
R@1 : 63.690
0it [00:00, ?it/s]
R@2 : 75.169
R@4 : 83.103
R@8 : 89.787
R@16 : 94.092
R@32 : 96.523






Train Epoch: 4 [56/65 (85%)] Loss: 8.642567: : 56it [00:12,  4.48it/s]


Train Epoch: 4 [65/65 (98%)] Loss: 8.984283: : 65it [00:15,  4.30it/s]
Computing t-SNE embedding
R@1 : 66.138
0it [00:00, ?it/s]
R@2 : 76.823
R@4 : 85.010
R@8 : 90.766
R@16 : 94.429
R@32 : 97.215







Train Epoch: 5 [64/65 (97%)] Loss: 9.105371: : 64it [00:14,  4.60it/s]

Train Epoch: 5 [65/65 (98%)] Loss: 8.586621: : 65it [00:15,  4.27it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 63.758
Train Epoch: 6 [4/65 (5%)] Loss: 8.440611: : 4it [00:01,  3.48it/s]
R@2 : 75.692
R@4 : 83.997
R@8 : 90.074
R@16 : 94.497






Train Epoch: 6 [56/65 (85%)] Loss: 7.040181: : 56it [00:13,  4.39it/s]


Train Epoch: 6 [65/65 (98%)] Loss: 7.767461: : 65it [00:15,  4.29it/s]
Computing t-SNE embedding
R@1 : 65.159
0it [00:00, ?it/s]
R@2 : 76.300
R@4 : 84.639
R@8 : 90.935
R@16 : 94.700
R@32 : 97.248







Train Epoch: 7 [63/65 (95%)] Loss: 6.950388: : 63it [00:15,  4.44it/s]

Train Epoch: 7 [65/65 (98%)] Loss: 6.934707: : 65it [00:15,  4.17it/s]
0it [00:00, ?it/s]
Computing t-SNE embedding
R@1 : 66.053
R@2 : 76.570
R@4 : 85.263
R@8 : 90.598
R@16 : 94.716
R@32 : 96.962







Train Epoch: 8 [64/65 (97%)] Loss: 7.100752: : 64it [00:15,  4.55it/s]

Train Epoch: 8 [65/65 (98%)] Loss: 6.682018: : 65it [00:15,  4.23it/s]
Computing t-SNE embedding
R@1 : 66.290
0it [00:00, ?it/s]
R@2 : 77.465
R@4 : 85.668
R@8 : 91.053
R@16 : 94.683
R@32 : 97.265







Train Epoch: 9 [62/65 (94%)] Loss: 6.472431: : 62it [00:14,  4.35it/s]

Train Epoch: 9 [65/65 (98%)] Loss: 6.670452: : 65it [00:15,  4.15it/s]
Computing t-SNE embedding
R@1 : 66.087
0it [00:00, ?it/s]
R@2 : 76.435
R@4 : 85.348
R@8 : 90.817
R@16 : 94.598
R@32 : 97.232







Train Epoch: 10 [63/65 (95%)] Loss: 6.383701: : 63it [00:15,  4.31it/s]

Train Epoch: 10 [65/65 (98%)] Loss: 6.063128: : 65it [00:15,  4.16it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 66.560
Train Epoch: 11 [3/65 (3%)] Loss: 6.263690: : 3it [00:01,  2.67it/s]
R@2 : 77.870
R@4 : 86.242
R@8 : 91.492
R@16 : 94.936








Train Epoch: 11 [65/65 (98%)] Loss: 6.089948: : 65it [00:16,  4.39it/s]

Train Epoch: 11 [65/65 (98%)] Loss: 6.089948: : 65it [00:16,  3.83it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 66.610
Train Epoch: 12 [3/65 (3%)] Loss: 6.553345: : 3it [00:01,  2.68it/s]
R@2 : 77.228
R@4 : 85.517
R@8 : 91.239
R@16 : 94.885







Train Epoch: 12 [64/65 (97%)] Loss: 6.199148: : 64it [00:14,  4.57it/s]

Train Epoch: 12 [65/65 (98%)] Loss: 6.014439: : 65it [00:15,  4.26it/s]
Computing t-SNE embedding
R@1 : 67.151
0it [00:00, ?it/s]
R@2 : 77.735
R@4 : 86.040
R@8 : 91.492
R@16 : 95.054
R@32 : 97.248







Train Epoch: 13 [62/65 (94%)] Loss: 6.218049: : 62it [00:14,  4.30it/s]

Train Epoch: 13 [65/65 (98%)] Loss: 5.953345: : 65it [00:15,  4.14it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
Train Epoch: 14 [4/65 (5%)] Loss: 5.906560: : 4it [00:01,  3.57it/s]
R@1 : 66.931
R@2 : 77.735
R@4 : 86.023
R@8 : 91.627
R@16 : 95.138







Train Epoch: 14 [64/65 (97%)] Loss: 5.916646: : 64it [00:14,  4.57it/s]

Train Epoch: 14 [65/65 (98%)] Loss: 5.971337: : 65it [00:15,  4.28it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 67.319
R@2 : 77.971
R@4 : 86.141
R@8 : 91.830
R@16 : 95.240
R@32 : 97.265







Train Epoch: 15 [64/65 (97%)] Loss: 6.288256: : 64it [00:14,  4.61it/s]

Train Epoch: 15 [65/65 (98%)] Loss: 5.833350: : 65it [00:15,  4.27it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 67.134
Train Epoch: 16 [2/65 (2%)] Loss: 5.891943: : 2it [00:00,  2.32it/s]
R@2 : 78.393
R@4 : 86.090
R@8 : 92.032
R@16 : 95.392







Train Epoch: 16 [65/65 (98%)] Loss: 6.073525: : 65it [00:15,  4.23it/s]
**Evaluating...**
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 67.353
Train Epoch: 17 [2/65 (2%)] Loss: 5.420339: : 2it [00:00,  2.28it/s]
R@2 : 77.802
R@4 : 85.736
R@8 : 91.627
R@16 : 95.020








Train Epoch: 17 [65/65 (98%)] Loss: 5.492225: : 65it [00:15,  4.25it/s]
**Evaluating...**
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 66.762
Train Epoch: 18 [3/65 (3%)] Loss: 5.754491: : 3it [00:01,  2.87it/s]
R@2 : 77.194
R@4 : 85.517
R@8 : 91.340
R@16 : 94.851








Train Epoch: 18 [65/65 (98%)] Loss: 5.788352: : 65it [00:15,  4.12it/s]
**Evaluating...**
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 67.032
R@2 : 77.684
R@4 : 85.753
R@8 : 91.610
R@16 : 95.172
R@32 : 97.384







Train Epoch: 19 [62/65 (94%)] Loss: 5.602058: : 62it [00:15,  4.26it/s]

Train Epoch: 19 [65/65 (98%)] Loss: 5.612186: : 65it [00:15,  4.09it/s]
0it [00:00, ?it/s]
Computing t-SNE embedding
R@1 : 66.847
Train Epoch: 20 [2/65 (2%)] Loss: 5.394766: : 2it [00:00,  2.36it/s]
R@2 : 77.026
R@4 : 85.381
R@8 : 91.543
R@16 : 95.206







Train Epoch: 20 [64/65 (97%)] Loss: 5.524579: : 64it [00:15,  4.56it/s]

Train Epoch: 20 [65/65 (98%)] Loss: 5.432144: : 65it [00:15,  4.19it/s]
/home/wyf/Proxy_Anchor/utils.py:187: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(80,60))
0it [00:00, ?it/s]
Computing t-SNE embedding
R@1 : 67.117
R@2 : 77.887
R@4 : 85.719
R@8 : 91.729
R@16 : 95.324
R@32 : 97.485







Train Epoch: 21 [63/65 (95%)] Loss: 5.336864: : 63it [00:14,  4.48it/s]

Train Epoch: 21 [65/65 (98%)] Loss: 5.376296: : 65it [00:15,  4.22it/s]
0it [00:00, ?it/s]
Computing t-SNE embedding
Train Epoch: 22 [3/65 (3%)] Loss: 5.797508: : 3it [00:01,  3.03it/s]
R@1 : 66.965
R@2 : 78.089
R@4 : 86.175
R@8 : 91.712
R@16 : 95.240








Train Epoch: 22 [65/65 (98%)] Loss: 5.255313: : 65it [00:16,  3.98it/s]
**Evaluating...**
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 66.948
R@2 : 77.802
R@4 : 86.445
R@8 : 91.931
R@16 : 95.409
R@32 : 97.400







Train Epoch: 23 [62/65 (94%)] Loss: 5.369083: : 62it [00:14,  4.37it/s]

Train Epoch: 23 [65/65 (98%)] Loss: 5.507989: : 65it [00:15,  4.11it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 67.454
Train Epoch: 24 [3/65 (3%)] Loss: 5.431909: : 3it [00:01,  3.04it/s]
R@2 : 77.768
R@4 : 86.090
R@8 : 92.016
R@16 : 95.257







Train Epoch: 24 [64/65 (97%)] Loss: 5.433205: : 64it [00:14,  4.52it/s]

Train Epoch: 24 [65/65 (98%)] Loss: 5.660429: : 65it [00:15,  4.27it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 67.573
R@2 : 77.870
R@4 : 86.310
R@8 : 92.016
R@16 : 95.273
R@32 : 97.384







Train Epoch: 25 [63/65 (95%)] Loss: 5.378058: : 63it [00:14,  4.46it/s]

Train Epoch: 25 [65/65 (98%)] Loss: 5.487780: : 65it [00:15,  4.19it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 66.999
R@2 : 77.836
R@4 : 86.057
R@8 : 91.442
R@16 : 95.122
R@32 : 97.400







Train Epoch: 26 [65/65 (98%)] Loss: 5.447724: : 65it [00:15,  4.24it/s]
**Evaluating...**
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 67.471
R@2 : 78.190
R@4 : 86.361
R@8 : 91.695
R@16 : 95.155
R@32 : 97.248







Train Epoch: 27 [64/65 (97%)] Loss: 5.405282: : 64it [00:14,  4.54it/s]

Train Epoch: 27 [65/65 (98%)] Loss: 5.224424: : 65it [00:15,  4.27it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
Train Epoch: 28 [2/65 (2%)] Loss: 5.573968: : 2it [00:00,  2.33it/s]
R@1 : 67.066
R@2 : 78.241
R@4 : 86.496
R@8 : 91.864
R@16 : 95.290








Train Epoch: 28 [65/65 (98%)] Loss: 5.397377: : 65it [00:15,  4.26it/s]
**Evaluating...**
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 66.864
Train Epoch: 29 [1/65 (0%)] Loss: 5.363691: : 1it [00:00,  1.34it/s]
R@2 : 78.174
R@4 : 86.445
R@8 : 91.779
R@16 : 95.122




Train Epoch: 29 [39/65 (58%)] Loss: 5.495842: : 39it [00:09,  4.18it/s]
Traceback (most recent call last):
  File "train.py", line 505, in <module>
    main()
  File "train.py", line 423, in main
    loss = criterion(m, y.squeeze().cuda())
KeyboardInterrupt