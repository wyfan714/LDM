
Random Sampling
Train Epoch: 0 [1/65 (0%)] Loss: 19.939602: : 1it [00:00,  1.13it/s]
Training parameters: {'LOG_DIR': '../Proxy_Anchor/Newlogs', 'dataset': 'cub', 'sz_embedding': 512, 'sz_batch': 90, 'nb_epochs': 40, 'gpu_id': 1, 'nb_workers': 2, 'model': 'bn_inception', 'loss': 'Proxy_Anchor', 'optimizer': 'adamw', 'lr': 0.0001, 'mrg_lr': 0.0005, 'weight_decay': 0.0001, 'weight_lambda': 0.3, 'lr_decay_step': 10, 'lr_decay_gamma': 0.5, 'mrg_lr_decay_step': 10, 'mrg_lr_decay_gamma': 0.5, 'alphap': 48.0, 'alphan': 48.0, 'mrg': 0.1, 'IPC': None, 'warm': 1, 'bn_freeze': 1, 'l2_norm': 1, 'remark': '', 'delta': 0.1, 'T': 1.0, 'lam': 1.0}







Train Epoch: 0 [65/65 (98%)] Loss: 14.744200: : 65it [00:14,  4.52it/s]

Train Epoch: 0 [65/65 (98%)] Loss: 14.744200: : 65it [00:15,  4.32it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 50.456
R@2 : 63.825
R@4 : 76.199
R@8 : 85.213
R@16 : 91.847
R@32 : 95.949







Train Epoch: 1 [63/65 (95%)] Loss: 12.416454: : 63it [00:14,  4.45it/s]

Train Epoch: 1 [65/65 (98%)] Loss: 13.582344: : 65it [00:15,  4.24it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
Train Epoch: 2 [1/65 (0%)] Loss: 11.960685: : 1it [00:00,  1.30it/s]
R@1 : 60.331
R@2 : 72.282
R@4 : 82.073
R@8 : 88.538
R@16 : 93.585








Train Epoch: 2 [65/65 (98%)] Loss: 11.011791: : 65it [00:15,  4.21it/s]
**Evaluating...**
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 62.407
R@2 : 73.852
R@4 : 83.356
R@8 : 89.467
R@16 : 94.244
R@32 : 97.130






Train Epoch: 3 [55/65 (83%)] Loss: 9.629293: : 55it [00:12,  4.54it/s]


Train Epoch: 3 [65/65 (98%)] Loss: 9.825978: : 65it [00:15,  4.27it/s]
Computing t-SNE embedding
R@1 : 64.061
0it [00:00, ?it/s]
R@2 : 75.118
R@4 : 83.660
R@8 : 89.990
R@16 : 94.413
R@32 : 97.012







Train Epoch: 4 [64/65 (97%)] Loss: 8.894998: : 64it [00:14,  4.51it/s]

Train Epoch: 4 [65/65 (98%)] Loss: 9.165915: : 65it [00:15,  4.27it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 65.783
R@2 : 76.621
R@4 : 84.706
R@8 : 90.496
R@16 : 94.564
R@32 : 96.691







Train Epoch: 5 [62/65 (94%)] Loss: 8.002148: : 62it [00:14,  4.35it/s]

Train Epoch: 5 [65/65 (98%)] Loss: 8.392590: : 65it [00:15,  4.14it/s]
Computing t-SNE embedding
R@1 : 63.623
0it [00:00, ?it/s]
R@2 : 74.629
R@4 : 83.221
R@8 : 89.500
R@16 : 93.957
R@32 : 96.962







Train Epoch: 6 [64/65 (97%)] Loss: 7.692599: : 64it [00:14,  4.54it/s]

Train Epoch: 6 [65/65 (98%)] Loss: 7.857369: : 65it [00:15,  4.26it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 65.479
Train Epoch: 7 [2/65 (2%)] Loss: 6.741901: : 2it [00:00,  2.30it/s]
R@2 : 76.756
R@4 : 84.605
R@8 : 90.733
R@16 : 94.581








Train Epoch: 7 [65/65 (98%)] Loss: 6.825047: : 65it [00:15,  4.26it/s]
**Evaluating...**
Computing t-SNE embedding
R@1 : 66.138
0it [00:00, ?it/s]
R@2 : 76.806
R@4 : 84.909
R@8 : 91.003
R@16 : 94.750
R@32 : 97.012







Train Epoch: 8 [64/65 (97%)] Loss: 7.271060: : 64it [00:14,  4.48it/s]

Train Epoch: 8 [65/65 (98%)] Loss: 6.835476: : 65it [00:15,  4.23it/s]
0it [00:00, ?it/s]
Computing t-SNE embedding
Train Epoch: 9 [1/65 (0%)] Loss: 6.582525: : 1it [00:00,  1.27it/s]
R@1 : 66.779
R@2 : 77.161
R@4 : 85.297
R@8 : 91.020
R@16 : 94.936







Train Epoch: 9 [63/65 (95%)] Loss: 6.268889: : 63it [00:14,  4.48it/s]

Train Epoch: 9 [65/65 (98%)] Loss: 6.834638: : 65it [00:15,  4.22it/s]
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 66.796
Train Epoch: 10 [1/65 (0%)] Loss: 6.412135: : 1it [00:00,  1.32it/s]
R@2 : 77.954
R@4 : 85.888
R@8 : 91.020
R@16 : 94.733








Train Epoch: 10 [65/65 (98%)] Loss: 5.880282: : 65it [00:15,  4.20it/s]
**Evaluating...**
Computing t-SNE embedding
0it [00:00, ?it/s]
R@1 : 66.475
Train Epoch: 11 [2/65 (2%)] Loss: 6.190009: : 2it [00:00,  2.28it/s]
R@2 : 77.431
R@4 : 85.601
R@8 : 91.003
R@16 : 94.700







Train Epoch: 11 [64/65 (97%)] Loss: 6.055072: : 64it [00:14,  4.56it/s]

Train Epoch: 11 [65/65 (98%)] Loss: 6.094952: : 65it [00:15,  4.26it/s]
0it [00:00, ?it/s]
Computing t-SNE embedding
R@1 : 66.965
R@2 : 77.971
R@4 : 85.398
R@8 : 91.188
R@16 : 95.071
R@32 : 97.130







Train Epoch: 12 [62/65 (94%)] Loss: 6.043917: : 62it [00:14,  3.83it/s]

Train Epoch: 12 [65/65 (98%)] Loss: 6.023016: : 65it [00:15,  4.13it/s]
Traceback (most recent call last):
  File "train.py", line 505, in <module>
    main()
  File "train.py", line 462, in main
    Recalls = utils.evaluate_cos(model, dl_ev)
  File "/home/wyf/Proxy_Anchor/utils.py", line 85, in evaluate_cos
    def evaluate_cos(model, dataloader):
  File "/home/wyf/Proxy_Anchor/utils.py", line 63, in predict_batchwise1
    model.eval()
  File "/home/wyf/Proxy_Anchor/utils.py", line 63, in <listcomp>
    model.eval()
  File "/home/wyf/anaconda3/envs/proxyanchor/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/wyf/anaconda3/envs/proxyanchor/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/wyf/anaconda3/envs/proxyanchor/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1138, in _get_data
    success, data = self._try_get_data()
  File "/home/wyf/anaconda3/envs/proxyanchor/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/wyf/anaconda3/envs/proxyanchor/lib/python3.8/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/home/wyf/anaconda3/envs/proxyanchor/lib/python3.8/threading.py", line 306, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt